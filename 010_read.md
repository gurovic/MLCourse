```python
# –ß—Ç–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö –≤ pandas –¥–ª—è ML (Jupyter Notebook)

# !pip install pandas numpy matplotlib seaborn pyarrow fastparquet scipy cudf
```

---

## üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (Must Know –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–∏—Ö)

### 1.1 –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV
```python
import pandas as pd

# –ë–∞–∑–æ–≤—ã–π –ø—Ä–∏–º–µ—Ä
df = pd.read_csv('data.csv')

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è "–≥—Ä—è–∑–Ω—ã—Ö" –¥–∞–Ω–Ω—ã—Ö
df = pd.read_csv(
    'data.csv',
    sep=';',                 # –Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    encoding='latin1',       # –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã: 'utf-8' –∏–ª–∏ 'cp1251'
    na_values=['NA', '?'],   # –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏—è –ø—Ä–æ–ø—É—Å–∫–æ–≤
    parse_dates=['date_col'] # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–∏–Ω–≥ –¥–∞—Ç
)
```

### 1.2 –ü—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö
```python
print("–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:")
display(df.head())

print("\n–û—Å–Ω–æ–≤–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
display(df.describe(include='all'))

print("\n–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ç–∏–ø–∞—Ö:")
display(df.info())
```

### 1.3 –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
```python
df.to_csv('processed_data.csv', index=False)  # –±–µ–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏–Ω–¥–µ–∫—Å–æ–≤
df.to_excel('report.xlsx', sheet_name='Data')
```

### 1.4 –†–µ—à–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –ø—Ä–æ–±–ª–µ–º
```python
# –ü—Ä–æ–ø—É—Å–∫–∏: —É–¥–∞–ª–µ–Ω–∏–µ –∏–ª–∏ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ
df.dropna(subset=['important_col'], inplace=True)
df.fillna({'age': df['age'].median()}, inplace=True)

# –î—É–±–ª–∏–∫–∞—Ç—ã
df = df.drop_duplicates()
```

---

## üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å (–î–ª—è –æ–ø—ã—Ç–Ω—ã—Ö ML-–∏–Ω–∂–µ–Ω–µ—Ä–æ–≤)

### 2.1 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏
```python
# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Ç–∏–ø–æ–≤
def optimize_dtypes(df):
    for col in df.columns:
        col_type = df[col].dtype
        if col_type == 'int64':
            df[col] = pd.to_numeric(df[col], downcast='integer')
        elif col_type == 'float64':
            df[col] = pd.to_numeric(df[col], downcast='float')
    return df

df = optimize_dtypes(df)
print(f"–ü–∞–º—è—Ç—å: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
```

### 2.2 –†–∞–±–æ—Ç–∞ —Å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
```python
# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è + One-Hot Encoding –¥–ª—è –º–æ–¥–µ–ª–µ–π
df['category_col'] = df['category_col'].astype('category')
df = pd.get_dummies(df, columns=['category_col'], prefix='cat')
```

### 2.3 –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
```python
# –ß—Ç–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
cols = ['feature1', 'feature2', 'target']
df = pd.read_csv('big_data.csv', usecols=cols)

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –±–∏–Ω–∞—Ä–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–∞—Ö
df.to_parquet('data.parquet', engine='pyarrow')  # –±—ã—Å—Ç—Ä–µ–µ CSV –≤ 5-10x
```

### 2.4 –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å ML-–±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏
```python
from sklearn.model_selection import train_test_split

X = df.drop('target', axis=1).values
y = df['target'].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
```

---

## üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å (–î–ª—è —Ö–∞–∫–∞—Ç–æ–Ω–æ–≤ –∏ Kaggle Grandmasters)

### 3.1 –†–∞–±–æ—Ç–∞ —Å –≥–∏–≥–∞–±–∞–π—Ç–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
```python
# –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–æ–µ —á—Ç–µ–Ω–∏–µ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π
chunk_size = 10**5  # 100k —Å—Ç—Ä–æ–∫ –∑–∞ —Ä–∞–∑
filtered_rows = []

for chunk in pd.read_csv('terabyte_data.csv', chunksize=chunk_size):
    chunk = chunk[chunk['value'] > 0]  # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –Ω–∞ –ª–µ—Ç—É
    filtered_rows.append(chunk)

df = pd.concat(filtered_rows)
```

### 3.2 –†–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã –¥–ª—è —Ç–µ–∫—Å—Ç–æ–≤/NLP
```python
from sklearn.feature_extraction.text import TfidfVectorizer
from scipy.sparse import save_npz

vectorizer = TfidfVectorizer()
sparse_matrix = vectorizer.fit_transform(df['text'])

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–º —Å LibSVM
save_npz('sparse_data.npz', sparse_matrix)
```

### 3.3 GPU-—É—Å–∫–æ—Ä–µ–Ω–∏–µ —Å RAPIDS
```python
import cudf

# –ß—Ç–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU
gdf = cudf.read_csv('big_data.csv')
gdf = gdf.query('value > 0')  # —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –≤ 10-50x –±—ã—Å—Ç—Ä–µ–µ pandas

# –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ numpy –¥–ª—è –º–æ–¥–µ–ª–µ–π
X = gdf.to_pandas().values
```

### 3.4 –≠–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è
```python
# –£–º–µ–Ω—å—à–µ–Ω–∏–µ —Ç–æ—á–Ω–æ—Å—Ç–∏ float64 -> float16
df = df.astype({col: 'float16' for col in float_cols})

# –°–ª–æ–≤–∞—Ä–Ω–æ–µ —Å–∂–∞—Ç–∏–µ –¥–ª—è —Å—Ç—Ä–æ–∫
df['text'] = df['text'].astype('category').cat.codes

# –ü–∞—Ä—Ç–∏—Ü–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ –∫–ª—é—á—É
df.groupby('month').apply(lambda x: x.to_parquet(f"data_{x.name}.parquet"))
```

### 3.5 –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ (Online Learning)
```python
from sklearn.linear_model import SGDClassifier

model = SGDClassifier()
for chunk in pd.read_csv('stream.csv', chunksize=1000):
    X = chunk.drop('target', axis=1)
    y = chunk['target']
    model.partial_fit(X, y, classes=np.unique(y))
```

---

## üìä –ß–µ–∫–ª–∏—Å—Ç –ø–æ —É—Ä–æ–≤–Ω—è–º

| –£—Ä–æ–≤–µ–Ω—å | –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ |
|---------|---------------------|
| üü¢      | –ß—Ç–µ–Ω–∏–µ CSV/Excel, –±–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑, fillna/drop_duplicates |
| üü°      | –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Ç–∏–ø–æ–≤, –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏, parquet, train_test_split |
| üî¥      | –ò—Ç–µ—Ä–∞—Ç–∏–≤–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞, GPU-—É—Å–∫–æ—Ä–µ–Ω–∏–µ, —Ä–∞–∑—Ä–µ–∂–µ–Ω–Ω—ã–µ –º–∞—Ç—Ä–∏—Ü—ã, online learning |

---

## ‚ö†Ô∏è –ê–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã
- **–î–ª—è –≤—Å–µ—Ö —É—Ä–æ–≤–Ω–µ–π:** 
  - –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å –∏–Ω–¥–µ–∫—Å–æ–º (`index=True`)
  - –ß—Ç–µ–Ω–∏–µ –≤—Å–µ–≥–æ —Ñ–∞–π–ª–∞ –¥–ª—è –ø—Ä–µ–¥–ø—Ä–æ—Å–º–æ—Ç—Ä–∞ (–∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `nrows=1000`)
- **üî¥ –≠–∫—Å–ø–µ—Ä—Ç—ã:** 
  - –ù–µ–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ü–∏–∫–ª—ã –ø–æ DataFrame
  - –ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ `dtype` –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ –≥–∏–≥–∞–±–∞–π—Ç–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

```python
# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–º–µ—Ä–æ–≤ (–∑–∞–º–µ–Ω–∏—Ç–µ –ø—É—Ç–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
try:
    pd.read_csv('test_data.csv', nrows=10)
except FileNotFoundError:
    print("‚ö†Ô∏è –°–æ–∑–¥–∞–π—Ç–µ —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ sample –¥–∞–Ω–Ω—ã–µ!")
``` 

–≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ —à–∞–±–ª–æ–Ω –¥–ª—è –ø—Ä–æ–µ–∫—Ç–æ–≤: –∫–æ–ø–∏—Ä—É–π—Ç–µ —è—á–µ–π–∫–∏ –Ω—É–∂–Ω–æ–≥–æ —É—Ä–æ–≤–Ω—è –∏ –∞–¥–∞–ø—Ç–∏—Ä—É–π—Ç–µ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É.
