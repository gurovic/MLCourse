### –ì–ª–∞–≤–∞: Estimator –∏ Transformer –≤ scikit-learn  
*–û—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–µ –±–ª–æ–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è*

---

#### üß© –ß—Ç–æ —Ç–∞–∫–æ–µ Estimator?  
**Estimator (–û—Ü–µ–Ω—â–∏–∫)** - –ª—é–±–æ–π –æ–±—ä–µ–∫—Ç –≤ scikit-learn, –∫–æ—Ç–æ—Ä—ã–π:  
1. –ò–∑—É—á–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ `.fit()`  
2. –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∑–Ω–∞–Ω–∏—è —á–µ—Ä–µ–∑ `.transform()` –∏–ª–∏ `.predict()`  

```python
from sklearn.ensemble import RandomForestClassifier

# –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ü–µ–Ω—â–∏–∫–∞
estimator = RandomForestClassifier(n_estimators=100)

# –û–±—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
estimator.fit(X_train, y_train)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
predictions = estimator.predict(X_test)
```

**–ö–ª—é—á–µ–≤—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:**  
- –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã (`ClassifierMixin`)  
- –†–µ–≥—Ä–µ—Å—Å–æ—Ä—ã (`RegressorMixin`)  
- –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ç–æ—Ä—ã (`ClusterMixin`)  

---

#### üîÑ –ß—Ç–æ —Ç–∞–∫–æ–µ Transformer?  
**Transformer (–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å)** - —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π —Ç–∏–ø –æ—Ü–µ–Ω—â–∏–∫–∞, –∫–æ—Ç–æ—Ä—ã–π:  
1. –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ `.fit()`  
2. –ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∫ –¥–∞–Ω–Ω—ã–º —á–µ—Ä–µ–∑ `.transform()`  

```python
from sklearn.preprocessing import StandardScaler

# –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—è
transformer = StandardScaler()

# –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–≥–æ –∏ std
transformer.fit(X_train)

# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏
X_scaled = transformer.transform(X_train)
```

**–†–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã:**  
- `StandardScaler`/`MinMaxScaler` - –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ  
- `OneHotEncoder` - –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π  
- `SimpleImputer` - –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤  
- `PCA` - —É–º–µ–Ω—å—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏  

---

#### üß™ –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ —Ä–∞–±–æ—Ç—ã  
1. **–ù–µ–º–µ–∑–æ–∏–¥–Ω–æ—Å—Ç—å (Non-statefulness)**  
   –ü–æ—Å–ª–µ `.fit()` —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö —Å –Ω–∏–∂–Ω–∏–º –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ–º:  
   ```python
   print(transformer.mean_)  # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
   print(transformer.scale_)  # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è
   ```

2. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**  
   –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è—é—Ç:  
   - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ NaN –≤ `fit()`  
   - –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –≤ `transform()`  

3. **–ú–µ—Ç–æ–¥ `.fit_transform()`**  
   –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∞—Ü–∏—è –¥–ª—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è:  
   ```python
   X_encoded = OneHotEncoder().fit_transform(X_categorical)
   ```

---

#### üß© –ö–æ–º–ø–æ–∑–∏—Ü–∏—è: Pipeline  
–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –∏ –æ—Ü–µ–Ω—â–∏–∫–∏ –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤ —Ü–µ–ø–æ—á–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏:  
```python
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression

# –°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–∞
pipe = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),  # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä
    ('scaler', StandardScaler()),                   # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä
    ('classifier', LogisticRegression())            # –û—Ü–µ–Ω—â–∏–∫
])

# –ï–¥–∏–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≤—Å–µ–π —Ü–µ–ø–æ—á–∫–∏
pipe.fit(X_train, y_train)  # –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
pipe.predict(X_test)        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ + –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤:**  
- –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ data leakage  
- –£–ø—Ä–æ—â–µ–Ω–∏–µ deployment  
- –°–æ–≤–º–µ—Å—Ç–Ω–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤  

---

#### üõ†Ô∏è –°–æ–∑–¥–∞–Ω–∏–µ –∫–∞—Å—Ç–æ–º–Ω–æ–≥–æ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞  
```python
from sklearn.base import BaseEstimator, TransformerMixin

class LogTransformer(BaseEstimator, TransformerMixin):
    def __init__(self, add_const=1e-6):
        self.add_const = add_const
        
    def fit(self, X, y=None):
        return self  # –ù–∏—á–µ–≥–æ –Ω–µ –≤—ã—á–∏—Å–ª—è–µ–º –≤ fit
    
    def transform(self, X):
        return np.log(X + self.add_const)
        
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ
preprocessor = Pipeline([
    ('imputer', SimpleImputer()),
    ('log', LogTransformer())
])
```

**–û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã:**  
1. –ù–∞—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ—Ç `BaseEstimator` –∏ `TransformerMixin`  
2. –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –º–µ—Ç–æ–¥–æ–≤ `.fit()` –∏ `.transform()`  
3. `TransformerMixin` –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç `.fit_transform()`  

---

#### üí° –õ—É—á—à–∏–µ –ø—Ä–∞–∫—Ç–∏–∫–∏  
1. **–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π**  
   –í—Å–µ–≥–¥–∞ –¥–µ–ª–∞–π—Ç–µ `train_test_split()` –ø–µ—Ä–µ–¥ –≤—ã–∑–æ–≤–æ–º `.fit()` —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤  

2. **ColumnTransformer –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤**  
   ```python
   from sklearn.compose import ColumnTransformer
   
   preprocessor = ColumnTransformer([
       ('num', StandardScaler(), num_cols),
       ('cat', OneHotEncoder(), cat_cols)
   ])
   ```

3. **–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è**  
   –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—ã–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã:  
   ```python
   import joblib
   joblib.dump(transformer, 'scaler.pkl')
   ```

4. **–ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö**  
   –ü–æ—Å–ª–µ `transform()` –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ `.get_feature_names_out()` –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫  

---

**Golden Rule:**  
> "–í—Å–µ, —á—Ç–æ —É—á–∏—Ç—Å—è –Ω–∞ –¥–∞–Ω–Ω—ã—Ö - Estimator, –≤—Å–µ, —á—Ç–æ –º–µ–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ - Transformer,  
> –∞ Pipeline - —ç—Ç–æ –∫–ª–µ–π, –∫–æ—Ç–æ—Ä—ã–π –∏—Ö –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º—ã–π workflow."
