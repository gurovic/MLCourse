# –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äì MAE, Accuracy, F1 –∏ –¥—Ä.

## üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)

### 1.1 MAE (Mean Absolute Error)
**–î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:** –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞
```math
\text{MAE} = \frac{1}{N}\sum_{i=1}^{N} |\hat{y}_i - y_i| 
```
```python
y_true = np.array([3.0, 5.0, 2.5, 7.0])
y_pred = np.array([2.5, 5.0, 3.0, 8.0])
mae = mean_absolute_error(y_true, y_pred)
print(f"MAE: {mae:.2f}")  # (0.5+0+0.5+1)/4 = 0.5
```

> ‚ö†Ô∏è **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** MAE –Ω–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ –±–æ–ª—å—à–∏–º –æ—à–∏–±–∫–∞–º (–≤—ã–±—Ä–æ—Å–∞–º), –ø–æ—ç—Ç–æ–º—É –ª—É—á—à–µ –ø–æ–¥—Ö–æ–¥–∏—Ç, –µ—Å–ª–∏ –≤—ã–±—Ä–æ—Å–æ–≤ –º–Ω–æ–≥–æ.

---

### 1.2 Accuracy (–¢–æ—á–Ω–æ—Å—Ç—å)
**–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:** –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤  
```math
\text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}
```

```python
y_true = [0, 1, 0, 1, 1]
y_pred = [0, 1, 0, 0, 1]
acc = accuracy_score(y_true, y_pred)
print(f"Accuracy: {acc:.2f}")  # 4/5 = 0.8
```

> ‚ö†Ô∏è **–í–∞–∂–Ω–æ:** Accuracy –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±–º–∞–Ω—á–∏–≤ –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ –∫–ª–∞—Å—Å–æ–≤.

#### –ü—Ä–∏–º–µ—Ä:
```python
y_true = [0, 0, 0, 0, 1]
y_pred = [0, 0, 0, 0, 0]
print(accuracy_score(y_true, y_pred))  # 0.8 ‚Üí –Ω–æ –º–æ–¥–µ–ª—å –Ω–µ –≤–∏–¥–∏—Ç –∫–ª–∞—Å—Å 1!
```

---

### 1.3 F1-Score
**–ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ precision –∏ recall:**  
```math
F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
```

```python
f1 = f1_score(y_true, y_pred)
print(f"F1-Score: {f1:.2f}")  # Precision=0.67, Recall=0.67 ‚Üí F1=0.67
```

> ‚ö†Ô∏è –ü–æ—á–µ–º—É –≥–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ? –ß—Ç–æ–±—ã —à—Ç—Ä–∞—Ñ–æ–≤–∞—Ç—å —Å–ª—É—á–∞–∏, –≥–¥–µ –æ–¥–∏–Ω –∏–∑ –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π –æ—á–µ–Ω—å –Ω–∏–∑–∫–∏–π.

---

## üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å (–í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏)

### 2.1 –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏?

| –ó–∞–¥–∞—á–∞                     | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏                             |
|---------------------------|---------------------------------------------------|
| –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è    | F1, AUC-ROC, Precision, Recall                    |
| –ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è | F1-macro, Accuracy                                |
| –†–µ–≥—Ä–µ—Å—Å–∏—è                 | MAE, MSE, R¬≤                                      |
| –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ             | NDCG, MAP                                         |

---

### 2.2 –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫

```python
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ')
plt.ylabel('–ò—Å—Ç–∏–Ω–∞')
plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')
plt.show()
```

#### –†–∞—Å—á—ë—Ç –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç:
```python
tn, fp, fn, tp = cm.ravel()
print(f"TN={tn}, FP={fp}, FN={fn}, TP={tp}")
```

#### –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏:
- **Sensitivity (Recall)**: ```math \frac{TP}{TP + FN} ```
- **Specificity**: ```math \frac{TN}{TN + FP} ```
- **FPR (False Positive Rate)**: ```math \frac{FP}{FP + TN} ```

---

### 2.3 Precision-Recall Tradeoff

```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.plot(recalls, precisions)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('–ö—Ä–∏–≤–∞—è Precision-Recall')
plt.show()
```

> ‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π `precision_recall_curve()` –≤–º–µ—Å—Ç–æ —Ä—É—á–Ω–æ–≥–æ –ø–µ—Ä–µ–±–æ—Ä–∞ –ø–æ—Ä–æ–≥–æ–≤.

---

## üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å (–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏)

### 3.1 –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏

#### Weighted Accuracy:

```python
def weighted_accuracy(y_true, y_pred, weights=[0.5, 2.0]):
    correct = np.zeros(len(y_true))
    for i, (true, pred) in enumerate(zip(y_true, y_pred)):
        if true == pred:
            correct[i] = weights[true]
    return np.mean(correct)

print(f"Weighted Accuracy: {weighted_accuracy(y_true, y_pred):.2f}")
```

#### Cohen's Kappa:

```python
from sklearn.metrics import cohen_kappa_score

kappa = cohen_kappa_score(y_true, y_pred)
print(f"Cohen's Kappa: {kappa:.2f}")
```

#### Matthews Correlation Coefficient (MCC):

```python
from sklearn.metrics import matthews_corrcoef

mcc = matthews_corrcoef(y_true, y_pred)
print(f"MCC: {mcc:.2f}")
```

---

### 3.2 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫

```python
def profit_metric(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    return tp*10 - fp*1 - fn*5  # –ü—Ä–∏–±—ã–ª—å

print(f"Business Profit: ${profit_metric(y_true, y_pred)}")
```

> üí° –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –±–∏–∑–Ω–µ—Å-—Ü–µ–ª–∏.

---

### 3.3 LogLoss (Logarithmic Loss)

```python
from sklearn.metrics import log_loss

y_true_proba = [0, 1, 0, 1]
y_pred_proba = [0.1, 0.9, 0.2, 0.8]
logloss = log_loss(y_true_proba, y_pred_proba)
print(f"LogLoss: {logloss:.4f}")  # –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ
```

> ‚ö†Ô∏è LogLoss —à—Ç—Ä–∞—Ñ—É–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –Ω–µ–≤–µ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è—Ö. –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –º–æ–¥–µ–ª—å —É–≤–µ—Ä–µ–Ω–∞ –Ω–∞ 99%, —á—Ç–æ —ç—Ç–æ –∫–ª–∞—Å—Å 1, –∞ –Ω–∞ —Å–∞–º–æ–º –¥–µ–ª–µ —ç—Ç–æ 0 ‚Äî –±–æ–ª—å—à–æ–π —à—Ç—Ä–∞—Ñ.

---

### 3.4 –ö—Ä–∏–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

```python
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestClassifier

train_sizes, train_scores, test_scores = learning_curve(
    RandomForestClassifier(),
    X, y,
    cv=5,
    scoring='f1',
    train_sizes=np.linspace(0.1, 1.0, 5)
)

plt.plot(train_sizes, np.mean(train_scores, axis=1), label='Train')
plt.plot(train_sizes, np.mean(test_scores, axis=1), label='Validation')
plt.legend()
plt.title('Learning Curve F1-Score')
plt.xlabel('Training Size')
plt.ylabel('F1')
plt.show()
```

> ‚úÖ –ü–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–Ω—è—Ç—å, –ø–µ—Ä–µ–æ–±—É—á–∞–µ—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª—å –∏–ª–∏ –Ω–µ–¥–æ–æ–±—É—á–∞–µ—Ç—Å—è.

---

## üìä –ß–µ–∫–ª–∏—Å—Ç –ø–æ —É—Ä–æ–≤–Ω—è–º

| –£—Ä–æ–≤–µ–Ω—å | –ù–∞–≤—ã–∫–∏ |
|---------|--------|
| üü¢ | –†–∞—Å—á–µ—Ç MAE, Accuracy, F1 –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤ |
| üü° | –ê–Ω–∞–ª–∏–∑ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫, –∫—Ä–∏–≤—ã–µ PR, –≤—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫ |
| üî¥ | –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π, –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤ |

---

## ‚ö†Ô∏è –ê–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã

1. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Accuracy –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ**  
   *–ü—Ä–∏–º–µ—Ä:* 99% –∫–ª–∞—Å—Å–∞ 0 ‚Üí Accuracy 99%, –Ω–æ –º–æ–¥–µ–ª—å –±–µ—Å–ø–æ–ª–µ–∑–Ω–∞.
2. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è F1 –±–µ–∑ —É—á–µ—Ç–∞ business context**  
   *–†–∞–∑–Ω–∞—è —Ü–µ–Ω–∞ FP/FN.*
3. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ —Ä–∞–∑–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º**  
   *–ù–µ–ª—å–∑—è —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å F1 –∏ AUC-ROC –Ω–∞–ø—Ä—è–º—É—é.*
4. **–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤**  
   *–ù–µ –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã.*

---

## üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å–æ–≤–µ—Ç—ã

### –í—ã–±–æ—Ä –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:
```python
f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)
best_threshold = thresholds[np.argmax(f1_scores)]
print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {best_threshold:.2f}")
```

### –ë—É—Ç—Å—Ç—Ä—ç–ø –æ—Ü–µ–Ω–æ–∫:
```python
def bootstrap_metric(y_true, y_pred, metric, n_bootstrap=1000):
    scores = []
    for _ in range(n_bootstrap):
        indices = np.random.choice(len(y_true), size=len(y_true), replace=True)
        scores.append(metric(y_true[indices], y_pred[indices]))
    return np.percentile(scores, [2.5, 97.5])

print(f"95% CI –¥–ª—è F1: {bootstrap_metric(y_true, y_pred, f1_score)}")
```

### –ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:
```python
from sklearn.calibration import CalibratedClassifierCV, calibration_curve

model = RandomForestClassifier()
calibrated = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated.fit(X_train, y_train)
probs = calibrated.predict_proba(X_test)[:, 1]

# –ì—Ä–∞—Ñ–∏–∫ –∫–∞–ª–∏–±—Ä–æ–≤–∫–∏
fraction_of_positives, mean_predicted_value = calibration_curve(y_test, probs, n_bins=10)
plt.plot(mean_predicted_value, fraction_of_positives, "s-", label="Calibrated")
plt.plot([0, 1], [0, 1], "k:", label="Perfectly calibrated")
plt.legend()
plt.show()
```

---

## üìå –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è

### üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ MAE –¥–ª—è `y_true=[10, 20, 30]`, `y_pred=[12, 18, 28]`.
2. –í—ã—á–∏—Å–ª–∏—Ç–µ Accuracy –¥–ª—è `y_true=[1,0,1,0]`, `y_pred=[1,1,1,0]`.

### üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –î–ª—è `y_true=[1,0,1,1,0]`, `y_pred=[1,0,0,1,0]`:
   - –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫
   - –†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ Precision, Recall, F1
2. –û–±—ä—è—Å–Ω–∏—Ç–µ, –ø–æ—á–µ–º—É F1 –ª—É—á—à–µ Accuracy –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ.

### üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫—É Cohen's Kappa.
2. –°–æ–∑–¥–∞–π—Ç–µ –∫–∞—Å—Ç–æ–º–Ω—É—é –º–µ—Ç—Ä–∏–∫—É, –≥–¥–µ –æ—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∞ 1 –≤ 5 —Ä–∞–∑ –≤–∞–∂–Ω–µ–µ –∫–ª–∞—Å—Å–∞ 0.

---

## üìå –ó–∞–∫–ª—é—á–µ–Ω–∏–µ

### –ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
1. **–í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏**:
   - –ë–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è > —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
   - –î–∏—Å–±–∞–ª–∞–Ω—Å ‚Üí F1, AUC-ROC
   - –†–µ–≥—Ä–µ—Å—Å–∏—è ‚Üí MAE (–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å), MSE (—à—Ç—Ä–∞—Ñ –∑–∞ –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏)
2. **–í—Å–µ–≥–¥–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –æ—à–∏–±–∫–∏**:
   - –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ > Accuracy
   - –ö—Ä–∏–≤—ã–µ PR/ROC > F1
3. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å**:
   - –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
   - –ë—É—Ç—Å—Ç—Ä—ç–ø –æ—Ü–µ–Ω–∫–∏
4. **–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π** –¥–ª—è –∑–∞–¥–∞—á —Å –ø–æ—Ä–æ–≥–∞–º–∏

> üéØ –ü–æ–º–Ω–∏—Ç–µ: –Ω–µ—Ç "–ª—É—á—à–µ–π" –º–µ—Ç—Ä–∏–∫–∏ ‚Äî –µ—Å—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∞—è –¥–ª—è –≤–∞—à–µ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏!

