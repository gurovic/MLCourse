{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gurovic/MLCourse/blob/main/135_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB1v-hNlK2e0"
      },
      "source": [
        "# Перцептрон и однослойные нейронные сети"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaRJr4jBK2e2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuHYEz_hK2e4"
      },
      "source": [
        "## Идея перцептрона: биологическая аналогия\n",
        "\n",
        "Перцептрон, разработанный Фрэнком Розенблаттом в 1957 году, был вдохновлен биологическими нейронами. Рассмотрим аналогию:\n",
        "\n",
        "| **Биологический нейрон**       | **Искусственный нейрон**       |\n",
        "|-------------------------------|--------------------------------|\n",
        "| Дендриты (входные сигналы)    | Входные признаки (x₁, x₂, ...)|\n",
        "| Сома (тело нейрона)           | Сумматор + функция активации   |\n",
        "| Аксон (выходной сигнал)       | Выход (0 или 1)                |\n",
        "| Синапсы (соединения)          | Веса (w₁, w₂, ...)             |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nES1ZQmmK2e4"
      },
      "source": [
        "## Математическая модель перцептрона\n",
        "\n",
        "Формально перцептрон описывается:\n",
        "\n",
        "1. **Входной вектор**: $x = [x_1, x_2, ..., x_n]$\n",
        "2. **Веса модели**: $w = [w_1, w_2, ..., w_n]$\n",
        "3. **Функция активации** (ступенчатая):\n",
        "   \n",
        "   $$\n",
        "   f(z) =\n",
        "   \\begin{cases}\n",
        "   1 & \\text{если } z \\geq 0 \\\\\n",
        "   0 & \\text{иначе}\n",
        "   \\end{cases}\n",
        "   $$\n",
        "\n",
        "4. **Выход**: $y = f(w \\cdot x + b)$, где $b$ — смещение (bias)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DKOune1K2e5"
      },
      "outputs": [],
      "source": [
        "def step_function(z):\n",
        "    return 1 if z >= 0 else 0\n",
        "\n",
        "def perceptron_predict(x, weights, bias):\n",
        "    z = np.dot(weights, x) + bias\n",
        "    return step_function(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUPP-labK2e5"
      },
      "source": [
        "## Алгоритм обучения перцептрона\n",
        "\n",
        "Процедура обучения (правило Розенблатта):\n",
        "\n",
        "1. Инициализировать веса малыми случайными значениями\n",
        "2. Для каждого обучающего примера:\n",
        "   - Вычислить выход $y_{pred}$\n",
        "   - Обновить веса:\n",
        "     $$\n",
        "     w_i = w_i + \\eta (y_{true} - y_{pred}) x_i\n",
        "     $$\n",
        "     $$\n",
        "     b = b + \\eta (y_{true} - y_{pred})\n",
        "     $$\n",
        "   где $\\eta$ — скорость обучения (learning rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WOjk7gIK2e5"
      },
      "outputs": [],
      "source": [
        "class SimplePerceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=100):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                y_pred = step_function(linear_output)\n",
        "\n",
        "                update = self.lr * (y[idx] - y_pred)\n",
        "                self.weights += update * x_i\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return np.array([step_function(z) for z in linear_output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHVWiJB9K2e6"
      },
      "source": [
        "## Практическое применение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTqTp9drK2e6"
      },
      "source": [
        "### Линейно разделимые данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pofwwvsgK2e6"
      },
      "outputs": [],
      "source": [
        "# Генерация данных\n",
        "X, y = make_classification(\n",
        "    n_samples=100,\n",
        "    n_features=2,           # Общее количество признаков\n",
        "    n_informative=1,        # Информативные признаки\n",
        "    n_redundant=1,          # Избыточные признаки (линейные комбинации информативных)\n",
        "    n_repeated=0,           # Дублирующие признаки (точные копии других)\n",
        "    n_classes=2,\n",
        "    n_clusters_per_class=1,\n",
        "    random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "# Обучение перцептрона\n",
        "perceptron = SimplePerceptron(learning_rate=0.1, n_iters=100)\n",
        "perceptron.fit(X, y)\n",
        "\n",
        "# Визуализация\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X[:,0], X[:,1], c=y, cmap='cool')\n",
        "\n",
        "# Граница решения\n",
        "x_min, x_max = X[:,0].min()-1, X[:,0].max()+1\n",
        "y_min, y_max = X[:,1].min()-1, X[:,1].max()+1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
        "                     np.arange(y_min, y_max, 0.01))\n",
        "Z = perceptron.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
        "plt.contourf(xx, yy, Z, alpha=0.3)\n",
        "plt.title(\"Граница решения перцептрона\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZzSfGciK2e7"
      },
      "source": [
        "### Сравнение с sklearn Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "co6I6xetK2e7"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import Perceptron\n",
        "\n",
        "sk_perceptron = Perceptron(max_iter=100, eta0=0.1, random_state=42)\n",
        "sk_perceptron.fit(X, y)\n",
        "\n",
        "print(\"Наша реализация:\", accuracy_score(y, perceptron.predict(X)))\n",
        "print(\"Sklearn реализация:\", accuracy_score(y, sk_perceptron.predict(X)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CvGA5RYK2e7"
      },
      "source": [
        "## Ограничения перцептрона\n",
        "\n",
        "**Теорема о сходимости перцептрона** (Новиков, 1962):\n",
        "Если данные линейно разделимы, перцептрон гарантированно найдет разделяющую гиперплоскость за конечное число шагов.\n",
        "\n",
        "Однако:\n",
        "1. Не работает с нелинейно разделимыми данными (например, XOR)\n",
        "2. Чувствителен к масштабу данных\n",
        "3. Дает только линейные границы решений"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TnYkwnjK2e7"
      },
      "outputs": [],
      "source": [
        "# Пример с данными XOR (не решается перцептроном)\n",
        "X_xor = np.array([[0,0], [0,1], [1,0], [1,1]])\n",
        "y_xor = np.array([0, 1, 1, 0])\n",
        "\n",
        "xor_perceptron = SimplePerceptron(n_iters=1000)\n",
        "xor_perceptron.fit(X_xor, y_xor)\n",
        "print(\"Точность на XOR:\", accuracy_score(y_xor, xor_perceptron.predict(X_xor)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jou1suPhK2e8"
      },
      "source": [
        "## Вариации и модификации\n",
        "\n",
        "1. **Адалин (ADALINE)** - использует линейную функцию активации и минимизирует MSE\n",
        "2. **Многослойный перцептрон** - базовый строительный блок для нейронных сетей\n",
        "3. **Перцептрон с другими функциями активации** (сигмоид, ReLU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yba5B_8eK2e8"
      },
      "outputs": [],
      "source": [
        "class Adaline:\n",
        "    def __init__(self, learning_rate=0.01, n_iters=100):\n",
        "        self.lr = learning_rate\n",
        "        self.n_iters = n_iters\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_iters):\n",
        "            for idx, x_i in enumerate(X):\n",
        "                linear_output = np.dot(x_i, self.weights) + self.bias\n",
        "                error = y[idx] - linear_output\n",
        "                self.weights += self.lr * error * x_i\n",
        "                self.bias += self.lr * error\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(np.dot(X, self.weights) + self.bias >= 0, 1, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNOWWBWmK2e8"
      },
      "source": [
        "## Практические рекомендации\n",
        "\n",
        "1. **Масштабирование данных**:\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "```\n",
        "\n",
        "2. **Подбор скорости обучения**:\n",
        "   - Слишком большой η → колебания весов\n",
        "   - Слишком маленький η → медленная сходимость\n",
        "\n",
        "3. **Критерии остановки**:\n",
        "   - Максимальное число итераций\n",
        "   - Достижение заданной точности\n",
        "   - Отсутствие изменений весов\n",
        "\n",
        "## Упражнения\n",
        "\n",
        "1. Реализуйте перцептрон с сигмоидной функцией активации\n",
        "2. Сравните скорость сходимости при разных η\n",
        "3. Примените перцептрон к датасету iris (два класса)\n",
        "4. Визуализируйте изменение весов в процессе обучения"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример решения задания 3\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X_iris = iris.data[:100, :2]  # Берем только setosa и versicolor\n",
        "y_iris = iris.target[:100]\n",
        "\n",
        "perceptron_iris = SimplePerceptron(n_iters=100)\n",
        "perceptron_iris.fit(X_iris, y_iris)\n",
        "print(\"Точность на Iris:\", accuracy_score(y_iris, perceptron_iris.predict(X_iris)))"
      ],
      "metadata": {
        "id": "Y8ZvFYYfM2Tn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}