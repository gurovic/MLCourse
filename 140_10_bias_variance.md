# **Bias-Variance Tradeoff**

## **üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å: –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–Ω—è—Ç–∏—è –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏**

### **1. –ß—Ç–æ —Ç–∞–∫–æ–µ —Å–º–µ—â–µ–Ω–∏–µ (Bias)?**
**–°–º–µ—â–µ–Ω–∏–µ** ‚Äî –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å **—Å–ª–∏—à–∫–æ–º –ø—Ä–æ—Å—Ç–∞—è** –∏ –Ω–µ –º–æ–∂–µ—Ç —É–ª–æ–≤–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–∏.

**–ü—Ä–∏–º–µ—Ä —Å —Ü–µ–Ω–∞–º–∏ –Ω–∞ –¥–æ–º–∞:**  
- ü§ñ *–ú–æ–¥–µ–ª—å:* "–¶–µ–Ω–∞ –¥–æ–º–∞ = 100 000 + 1000 * –ø–ª–æ—â–∞–¥—å" (–ª–∏–Ω–µ–π–Ω–∞—è)  
- ‚ùå *–ü—Ä–æ–±–ª–µ–º–∞:* –ù–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —Ä–∞–π–æ–Ω, –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏, —ç—Ç–∞–∂  
- üìâ *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –í—Å–µ–≥–¥–∞ –∑–∞–Ω–∏–∂–∞–µ—Ç —Ü–µ–Ω—ã –≤ —Ü–µ–Ω—Ç—Ä–µ, –∑–∞–≤—ã—à–∞–µ—Ç –Ω–∞ –æ–∫—Ä–∞–∏–Ω–∞—Ö  

<img src="https://i.imgur.com/3Wl5s9G.png" width="500">

### **2. –ß—Ç–æ —Ç–∞–∫–æ–µ —Ä–∞–∑–±—Ä–æ—Å (Variance)?**
**–†–∞–∑–±—Ä–æ—Å** ‚Äî –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å **—Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è** –∏ –ø–æ–¥—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç—Å—è –ø–æ–¥ —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è.

**–ü—Ä–∏–º–µ—Ä —Å —Ü–µ–Ω–∞–º–∏ –Ω–∞ –¥–æ–º–∞:**  
- ü§ñ *–ú–æ–¥–µ–ª—å:* –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–∞–∂–¥—ã–π —á–∏—Ö - —à—É–º —Å—Ç—Ä–æ–π–∫–∏ —Ä—è–¥–æ–º, —Ü–≤–µ—Ç –¥–≤–µ—Ä–∏, –∏–º—è –ø—Ä–æ–¥–∞–≤—Ü–∞  
- ‚ùå *–ü—Ä–æ–±–ª–µ–º–∞:* –ù–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—à–∏–±–∞–µ—Ç—Å—è —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º  
- üìà *–†–µ–∑—É–ª—å—Ç–∞—Ç:* –í—á–µ—Ä–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–ª–∞ 10 –º–ª–Ω, —Å–µ–≥–æ–¥–Ω—è –Ω–∞ —Ç–∞–∫–æ–º –∂–µ –¥–æ–º–µ - 8 –º–ª–Ω  

<img src="https://i.imgur.com/5g5LZ7e.png" width="500">

### **3. –ò–¥–µ–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å**
**–•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å:**  
- –£—á–∏—Ç—ã–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã: –ø–ª–æ—â–∞–¥—å, —Ä–∞–π–æ–Ω, —ç—Ç–∞–∂–Ω–æ—Å—Ç—å ‚úÖ  
- –ò–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω—ã–µ –∫–æ–ª–µ–±–∞–Ω–∏—è: "–≤—á–µ—Ä–∞ –ø—Ä–æ–¥–∞–≤–µ—Ü –±—ã–ª –≤ –ø–ª–æ—Ö–æ–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–∏" ‚ùå  
- –°—Ç–∞–±–∏–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö üìä  

```python
# –ü—Å–µ–≤–¥–æ–∫–æ–¥ —Ö–æ—Ä–æ—à–µ–π –º–æ–¥–µ–ª–∏
def predict_price(house):
    base_price = 100_000
    price_per_sqm = 1_000 * house['district_coef']
    return base_price + price_per_sqm * house['area']
```

---

## **üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å: –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω–∞ –¥–∞–Ω–Ω—ã—Ö**

### **1. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ**
```python
import numpy as np
import matplotlib.pyplot as plt

# –ò—Å—Ç–∏–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å: —Ü–µ–Ω–∞ = 50 + 10 * ‚àö–ø–ª–æ—â–∞–¥—å
areas = np.linspace(20, 200, 100)
true_prices = 50 + 10 * np.sqrt(areas)

# –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã–π —à—É–º (—Ü–µ–Ω–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–Ω–æ–≥–∏—Ö —Ñ–∞–∫—Ç–æ—Ä–æ–≤)
np.random.seed(42)
noise = 20 * np.random.randn(100)
observed_prices = true_prices + noise

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(10, 6))
plt.scatter(areas, observed_prices, alpha=0.6, label='–†–µ–∞–ª—å–Ω—ã–µ —Å–¥–µ–ª–∫–∏')
plt.plot(areas, true_prices, 'g-', lw=3, label='–ò—Å—Ç–∏–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å')
plt.xlabel('–ü–ª–æ—â–∞–¥—å (–º¬≤)')
plt.ylabel('–¶–µ–Ω–∞ ($1000)')
plt.title('–†—ã–Ω–æ–∫ –Ω–µ–¥–≤–∏–∂–∏–º–æ—Å—Ç–∏: —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ')
plt.legend()
plt.grid(True)
plt.show()
```

### **2. –°—Ä–∞–≤–Ω–∏–º —Ç—Ä–∏ –º–æ–¥–µ–ª–∏**
```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.pipeline import make_pipeline

# –ü—Ä–æ—Å—Ç–∞—è –º–æ–¥–µ–ª—å (–ª–∏–Ω–µ–π–Ω–∞—è)
model_simple = LinearRegression()
model_simple.fit(areas.reshape(-1,1), observed_prices)
pred_simple = model_simple.predict(areas.reshape(-1,1))

# –•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å (–∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π –∫–æ—Ä–µ–Ω—å)
class SqrtTransformer:
    def fit(self, X, y=None): return self
    def transform(self, X): return np.sqrt(X)

model_good = make_pipeline(SqrtTransformer(), LinearRegression())
model_good.fit(areas.reshape(-1,1), observed_prices)
pred_good = model_good.predict(areas.reshape(-1,1))

# –°–ª–æ–∂–Ω–∞—è –º–æ–¥–µ–ª—å (–ø–æ–ª–∏–Ω–æ–º 10–π —Å—Ç–µ–ø–µ–Ω–∏)
model_complex = make_pipeline(PolynomialFeatures(10), LinearRegression())
model_complex.fit(areas.reshape(-1,1), observed_prices)
pred_complex = model_complex.predict(areas.reshape(-1,1))

# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
plt.figure(figsize=(12, 8))
plt.scatter(areas, observed_prices, alpha=0.3, label='–î–∞–Ω–Ω—ã–µ')
plt.plot(areas, true_prices, 'g-', lw=2, label='–ò—Å—Ç–∏–Ω–Ω–∞—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å')
plt.plot(areas, pred_simple, 'r--', lw=2, label='–õ–∏–Ω–µ–π–Ω–∞—è (high bias)')
plt.plot(areas, pred_good, 'b-', lw=2, label='–•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å (‚àöarea)')
plt.plot(areas, pred_complex, 'm--', lw=2, label='–ü–æ–ª–∏–Ω–æ–º 10–π —Å—Ç–µ–ø–µ–Ω–∏ (high variance)')
plt.xlabel('–ü–ª–æ—â–∞–¥—å (–º¬≤)')
plt.ylabel('–¶–µ–Ω–∞ ($1000)')
plt.legend()
plt.title('Bias-Variance Tradeoff –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–∏ —Ü–µ–Ω')
plt.grid(True)
plt.show()
```

**–ß—Ç–æ –≤–∏–¥–∏–º:**  
- üî¥ **–ö—Ä–∞—Å–Ω–∞—è –ª–∏–Ω–∏—è (high bias):** –°–ª–∏—à–∫–æ–º –ø—Ä—è–º–∞—è, –Ω–µ —É—á–∏—Ç—ã–≤–∞–µ—Ç —É–±—ã–≤–∞—é—â—É—é –æ—Ç–¥–∞—á—É –æ—Ç –ø–ª–æ—â–∞–¥–∏  
- üîµ **–°–∏–Ω—è—è –ª–∏–Ω–∏—è (–±–∞–ª–∞–Ω—Å):** –•–æ—Ä–æ—à–æ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –∏—Å—Ç–∏–Ω–Ω—É—é –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å  
- üü£ **–§–∏–æ–ª–µ—Ç–æ–≤–∞—è –ª–∏–Ω–∏—è (high variance):** –ü—ã—Ç–∞–µ—Ç—Å—è –ø—Ä–æ–π—Ç–∏ —á–µ—Ä–µ–∑ –≤—Å–µ —Ç–æ—á–∫–∏, –≤–∫–ª—é—á–∞—è —Å–ª—É—á–∞–π–Ω—ã–µ –≤—ã–±—Ä–æ—Å—ã  

---

## **üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å: –ö–∞–∫ –Ω–∞–π—Ç–∏ –∑–æ–ª–æ—Ç—É—é —Å–µ—Ä–µ–¥–∏–Ω—É?**

### **1. –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ –ø–æ –æ—à–∏–±–∫–∞–º**
```python
from sklearn.metrics import mean_squared_error

# –†–∞–∑–¥–µ–ª–∏–º –¥–∞–Ω–Ω—ã–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∏ —Ç–µ—Å—Ç–æ–≤—ã–µ
from sklearn.model_selection import train_test_split
X = areas.reshape(-1,1)
X_train, X_test, y_train, y_test = train_test_split(
    X, observed_prices, test_size=0.3, random_state=42
)

# –û–±—É—á–∏–º –º–æ–¥–µ–ª–∏
model_simple.fit(X_train, y_train)
model_good.fit(X_train, y_train)
model_complex.fit(X_train, y_train)

# –°—Ä–∞–≤–Ω–∏–º –æ—à–∏–±–∫–∏
print("–û—à–∏–±–∫–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
print(f"–õ–∏–Ω–µ–π–Ω–∞—è: {mean_squared_error(y_train, model_simple.predict(X_train)):.1f}")
print(f"–•–æ—Ä–æ—à–∞—è: {mean_squared_error(y_train, model_good.predict(X_train)):.1f}")
print(f"–ü–æ–ª–∏–Ω–æ–º: {mean_squared_error(y_train, model_complex.predict(X_train)):.1f}")

print("\n–û—à–∏–±–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:")
print(f"–õ–∏–Ω–µ–π–Ω–∞—è: {mean_squared_error(y_test, model_simple.predict(X_test)):.1f}")
print(f"–•–æ—Ä–æ—à–∞—è: {mean_squared_error(y_test, model_good.predict(X_test)):.1f}")
print(f"–ü–æ–ª–∏–Ω–æ–º: {mean_squared_error(y_test, model_complex.predict(X_test)):.1f}")
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:**  
```
–û—à–∏–±–∫–∏ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
–õ–∏–Ω–µ–π–Ω–∞—è: 350.4
–•–æ—Ä–æ—à–∞—è: 302.5
–ü–æ–ª–∏–Ω–æ–º: 250.1

–û—à–∏–±–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö:
–õ–∏–Ω–µ–π–Ω–∞—è: 390.7
–•–æ—Ä–æ—à–∞—è: 315.8
–ü–æ–ª–∏–Ω–æ–º: 450.3
```

**–ê–Ω–∞–ª–∏–∑:**  
- üìâ **–õ–∏–Ω–µ–π–Ω–∞—è –º–æ–¥–µ–ª—å:** –í—ã—Å–æ–∫–∏–µ –æ—à–∏–±–∫–∏ –≤–µ–∑–¥–µ (high bias)  
- ‚úÖ **–•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å:** –ë–∞–ª–∞–Ω—Å - –æ—à–∏–±–∫–∏ –±–ª–∏–∑–∫–∏  
- üìà **–ü–æ–ª–∏–Ω–æ–º:** –ú–∞–ª–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ, –±–æ–ª—å—à–∞—è –Ω–∞ —Ç–µ—Å—Ç–µ (high variance)  

### **2. –ö–∞–∫ —É–ª—É—á—à–∏—Ç—å –º–æ–¥–µ–ª–∏?**
**–î–ª—è –ª–∏–Ω–µ–π–Ω–æ–π –º–æ–¥–µ–ª–∏ (high bias):**  
- –î–æ–±–∞–≤–∏—Ç—å –Ω–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏: ‚àö–ø–ª–æ—â–∞–¥—å, —Ä–∞–π–æ–Ω, –≥–æ–¥ –ø–æ—Å—Ç—Ä–æ–π–∫–∏  
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–ª–∏–Ω–µ–π–Ω—É—é –º–æ–¥–µ–ª—å: –¥–µ—Ä–µ–≤–æ —Ä–µ—à–µ–Ω–∏–π  

**–î–ª—è –ø–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ (high variance):**  
- –£–ø—Ä–æ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å: —É–º–µ–Ω—å—à–∏—Ç—å —Å—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞  
- –î–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é  
- –£–≤–µ–ª–∏—á–∏—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö  

```python
# –ü—Ä–∏–º–µ—Ä —É–ª—É—á—à–µ–Ω–∏—è: Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏—è —Å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–µ–π
from sklearn.linear_model import Ridge

model_improved = make_pipeline(
    PolynomialFeatures(5),  # –£–º–µ–Ω—å—à–∏–ª–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
    Ridge(alpha=10.0)       # –î–æ–±–∞–≤–∏–ª–∏ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é
)
model_improved.fit(X_train, y_train)

print(f"–£–ª—É—á—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Ç–µ—Å—Ç MSE: {mean_squared_error(y_test, model_improved.predict(X_test)):.1f}")
```

### **3. –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—è –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏**
```python
from sklearn.model_selection import cross_val_score

degrees = range(1, 15)
cv_scores = []

for d in degrees:
    model = make_pipeline(PolynomialFeatures(d), LinearRegression())
    scores = cross_val_score(model, X, observed_prices, cv=5, scoring='neg_mean_squared_error')
    cv_scores.append(-np.mean(scores))

# –ù–∞–π–¥–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é —Å—Ç–µ–ø–µ–Ω—å
optimal_degree = degrees[np.argmin(cv_scores)]

plt.figure(figsize=(10, 6))
plt.plot(degrees, cv_scores, 'o-')
plt.axvline(optimal_degree, color='r', linestyle='--')
plt.xlabel('–°—Ç–µ–ø–µ–Ω—å –ø–æ–ª–∏–Ω–æ–º–∞')
plt.ylabel('–û—à–∏–±–∫–∞ (MSE)')
plt.title('–ü–æ–¥–±–æ—Ä –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏')
plt.grid(True)
plt.show()
```

---

## **üìä –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏**

### **–ö–æ–≥–¥–∞ —á—Ç–æ –¥–µ–ª–∞—Ç—å:**
| **–°–∏–º–ø—Ç–æ–º—ã** | **–î–∏–∞–≥–Ω–æ–∑** | **–õ–µ—á–µ–Ω–∏–µ** |
|--------------|-------------|-------------|
| –í—ã—Å–æ–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ –∏ —Ç–µ—Å—Ç–µ | High bias | –£–≤–µ–ª–∏—á–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏, –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ |
| –ù–∏–∑–∫–∞—è –æ—à–∏–±–∫–∞ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ, –≤—ã—Å–æ–∫–∞—è –Ω–∞ —Ç–µ—Å—Ç–µ | High variance | –£–ø—Ä–æ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª—å, –¥–æ–±–∞–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—é |
| –û—à–∏–±–∫–∏ –±–ª–∏–∑–∫–∏, –Ω–æ –≤—ã—Å–æ–∫–∏ | –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –µ–º–∫–æ—Å—Ç—å | –£–≤–µ–ª–∏—á–∏—Ç—å —Å–ª–æ–∂–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ |

### **–ó–æ–ª–æ—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞:**
1. –í—Å–µ–≥–¥–∞ –Ω–∞—á–∏–Ω–∞–π—Ç–µ —Å –ø—Ä–æ—Å—Ç–æ–π –º–æ–¥–µ–ª–∏ (–ª–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)
2. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è –æ—Ü–µ–Ω–∫–∏
3. –ü–æ—Å—Ç–µ–ø–µ–Ω–Ω–æ —É–≤–µ–ª–∏—á–∏–≤–∞–π—Ç–µ —Å–ª–æ–∂–Ω–æ—Å—Ç—å
4. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–π—Ç–µ—Å—å, –∫–æ–≥–¥–∞ —Ç–µ—Å—Ç–æ–≤–∞—è –æ—à–∏–±–∫–∞ –Ω–∞—á–∏–Ω–∞–µ—Ç —Ä–∞—Å—Ç–∏
5. –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è ‚Äî –≤–∞—à –¥—Ä—É–≥ –ø—Ä–æ—Ç–∏–≤ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è

> "–•–æ—Ä–æ—à–∞—è –º–æ–¥–µ–ª—å –∫–∞–∫ —Ö–æ—Ä–æ—à–∏–π —Ä–∏–µ–ª—Ç–æ—Ä: —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤–∞–∂–Ω—ã–µ —Ñ–∞–∫—Ç–æ—Ä—ã (–ø–ª–æ—â–∞–¥—å, —Ä–∞–π–æ–Ω), –∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ–µ (–ø–æ–≥–æ–¥–∞ –≤ –¥–µ–Ω—å –ø—Ä–æ—Å–º–æ—Ç—Ä–∞), –∏ –¥–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"

**–ü—Ä–∏–º–µ—Ä—ã —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏:**  
```python
# Ridge —Ä–µ–≥—Ä–µ—Å—Å–∏—è (L2 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)
from sklearn.linear_model import Ridge
model = Ridge(alpha=1.0)  # –ß–µ–º –±–æ–ª—å—à–µ alpha, —Ç–µ–º —Å–∏–ª—å–Ω–µ–µ —É–ø—Ä–æ—â–∞–µ–º

# Lasso —Ä–µ–≥—Ä–µ—Å—Å–∏—è (L1 —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)
from sklearn.linear_model import Lasso
model = Lasso(alpha=0.1)  # –ú–æ–∂–µ—Ç –æ–±–Ω—É–ª—è—Ç—å –Ω–µ–≤–∞–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
```
