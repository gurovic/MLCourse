
# –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ ‚Äì One-Hot, Target Encoding

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from category_encoders import TargetEncoder, CatBoostEncoder
from sklearn.model_selection import train_test_split

# !pip install category_encoders scikit-learn
```

---

## üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã)

### 1.1 One-Hot Encoding (OHE)
**–ü—Ä–∏–Ω—Ü–∏–ø:** –°–æ–∑–¥–∞–Ω–∏–µ –±–∏–Ω–∞—Ä–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏  
**–ü–ª—é—Å—ã:**  
- –ü—Ä–æ—Å—Ç–æ—Ç–∞ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏  
- –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è—Ö  
**–ú–∏–Ω—É—Å—ã:**  
- –ü—Ä–æ–∫–ª—è—Ç–∏–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –≤—ã—Å–æ–∫–æ–π –∫–∞—Ä–¥–∏–Ω–∞–ª—å–Ω–æ—Å—Ç—å—é  

```python
# –ü—Ä–∏–º–µ—Ä
data = pd.DataFrame({'color': ['red', 'blue', 'green', 'blue']})

# –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø–æ–¥—Ö–æ–¥
ohe = OneHotEncoder(sparse=False, handle_unknown='ignore')
ohe_data = ohe.fit_transform(data[['color']])
print(ohe_data)
# [[0. 1. 0.]
#  [1. 0. 0.]
#  [0. 0. 1.]
#  [1. 0. 0.]]
```

### 1.2 Frequency Encoding
**–ü—Ä–∏–Ω—Ü–∏–ø:** –ó–∞–º–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–π –Ω–∞ —á–∞—Å—Ç–æ—Ç—É –∏—Ö –≤—Å—Ç—Ä–µ—á–∞–µ–º–æ—Å—Ç–∏  
**–õ—É—á—à–µ –≤—Å–µ–≥–æ:** –î–ª—è –¥–µ—Ä–µ–≤—å–µ–≤ –∏ –∞–Ω—Å–∞–º–±–ª–µ–π  

```python
freq = data['color'].value_counts(normalize=True)
data['color_freq'] = data['color'].map(freq)
print(data)
```

### 1.3 Label Encoding
**–ü—Ä–∏–Ω—Ü–∏–ø:** –ü—Ä–∏—Å–≤–æ–µ–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –º–µ—Ç–æ–∫ (0, 1, 2,...)  
**–û—Å—Ç–æ—Ä–æ–∂–Ω–æ:** –ù–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫)  

```python
data['color_label'] = data['color'].astype('category').cat.codes
print(data)
```

---

## üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å (Target-Based Encoding)

### 2.1 –ë–∞–∑–æ–≤—ã–π Target Encoding
**–ü—Ä–∏–Ω—Ü–∏–ø:** –ó–∞–º–µ–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–∞ —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π  
**–†–∏—Å–∫:** –£—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏  

```python
# –û–ø–∞—Å–Ω—ã–π —Å–ø–æ—Å–æ–± (—É—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö)
data = pd.DataFrame({
    'city': ['A','A','B','B','C','C'],
    'price': [100, 120, 200, 180, 300, 320]
})

# –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ!
data['city_target'] = data.groupby('city')['price'].transform('mean')

# –ü—Ä–∞–≤–∏–ª—å–Ω–æ (—á–µ—Ä–µ–∑ split)
train, test = train_test_split(data, test_size=0.3)
means = train.groupby('city')['price'].mean()
test['city_target'] = test['city'].map(means)
```

### 2.2 –°–≥–ª–∞–∂–µ–Ω–Ω—ã–π Target Encoding
**–§–æ—Ä–º—É–ª–∞:**  
$encoded = \frac{mean \times n_{samples} + global\_mean \times \alpha}{n_{samples} + \alpha}$  

```python
encoder = TargetEncoder(smoothing=5.0)
train_encoded = encoder.fit_transform(train[['city']], train['price'])
test_encoded = encoder.transform(test[['city']])
```

### 2.3 CatBoost Encoding
**–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å:** –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ø—Ä–∏–Ω—Ü–∏–ø ordered boosting –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–∫–∏  

```python
encoder = CatBoostEncoder()
train_encoded = encoder.fit_transform(train[['city']], train['price'])
test_encoded = encoder.transform(test[['city']])
```

---

## üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å (–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏)

### 3.1 –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
```python
from sklearn.model_selection import KFold

def cross_val_encode(df, col, target, n_splits=5):
    df[f'{col}_encoded'] = np.nan
    kf = KFold(n_splits=n_splits)
    
    for train_idx, val_idx in kf.split(df):
        train = df.iloc[train_idx]
        val = df.iloc[val_idx]
        means = train.groupby(col)[target].mean()
        df.loc[val.index, f'{col}_encoded'] = val[col].map(means)
    
    return df

data = cross_val_encode(data, 'city', 'price')
```

### 3.2 –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —á–µ—Ä–µ–∑ NLP
```python
# –î–ª—è —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
from sklearn.feature_extraction.text import TfidfVectorizer

categories = ['electronics', 'books', 'home appliances']
vectorizer = TfidfVectorizer(max_features=10)
embeddings = vectorizer.fit_transform(categories)
print(embeddings.toarray())
```

### 3.3 –û–ø—Ç–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥ –∑–∞–¥–∞—á—É
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.pipeline import Pipeline

# –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö —Å—Ç—Ä–∞—Ç–µ–≥–∏–π
encoders = {
    'onehot': OneHotEncoder(),
    'target': TargetEncoder(),
    'catboost': CatBoostEncoder()
}

for name, encoder in encoders.items():
    model = Pipeline([
        ('encode', encoder),
        ('model', RandomForestRegressor())
    ])
    score = cross_val_score(model, X, y, cv=5).mean()
    print(f"{name}: {score:.4f}")
```

### 3.4 GPU-—É—Å–∫–æ—Ä–µ–Ω–∏–µ
```python
# –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ RAPIDS –¥–ª—è OHE
import cudf
gdf = cudf.from_pandas(data)
gdf_ohe = gdf.one_hot_encoding(column='city', prefix='city')
```

---

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤

| **–ú–µ—Ç–æ–¥**          | **–ü–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è**       | **–†–∏—Å–∫ —É—Ç–µ—á–∫–∏** | **–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å** |
|--------------------|------------------------|-----------------|-----------------|
| One-Hot            | –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏        | –ù–µ—Ç             | –í—ã—Å–æ–∫–∞—è         |
| Target Encoding    | –î–µ—Ä–µ–≤—å—è, –±—É—Å—Ç–∏–Ω–≥–∏      | –í—ã—Å–æ–∫–∏–π         | –ù–∏–∑–∫–∞—è          |
| CatBoost Encoding  | –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥    | –ù–∏–∑–∫–∏–π          | –ù–∏–∑–∫–∞—è          |
| Frequency Encoding | –ê–Ω—Å–∞–º–±–ª–∏               | –ù–µ—Ç             | –ù–∏–∑–∫–∞—è          |

---

## ‚ö†Ô∏è –ê–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã
1. **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ OHE –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º —Å >100 –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏** ‚Üí –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Target Encoding
2. **Target Encoding –±–µ–∑ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è** ‚Üí –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ
3. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Label Encoding –¥–ª—è –ª–∏–Ω–µ–π–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π** ‚Üí –ª–æ–∂–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
4. **–ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ—Å—Ç–∞ –æ—Ç–¥–µ–ª—å–Ω–æ –æ—Ç —Ç—Ä–µ–π–Ω–∞** ‚Üí —É—Ç–µ—á–∫–∞ –¥–∞–Ω–Ω—ã—Ö

---

## üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å–æ–≤–µ—Ç—ã
1. **–ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–¥—Ö–æ–¥–æ–≤:**
```python
data['city_ohe'] = OneHotEncoder().fit_transform(data[['city']])  # –î–ª—è –ª–∏–Ω–µ–π–Ω–æ–π —á–∞—Å—Ç–∏
data['city_target'] = TargetEncoder().fit_transform(data[['city']], data['price'])  # –î–ª—è –¥–µ—Ä–µ–≤—å–µ–≤
```

2. **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ:**
```python
class AdaptiveEncoder:
    def __init__(self, min_samples=50):
        self.min_samples = min_samples
        
    def encode(self, group, global_mean):
        n = len(group)
        alpha = max(self.min_samples - n, 0)
        return (group.mean() * n + global_mean * alpha) / (n + alpha)
```

3. **–í—Å—Ç—Ä–∞–∏–≤–∞–Ω–∏–µ –≤ –ø–∞–π–ø–ª–∞–π–Ω:**
```python
preprocessor = ColumnTransformer([
    ('ohe', OneHotEncoder(), ['color']),
    ('target', TargetEncoder(), ['city'])
])
pipeline = Pipeline([
    ('prep', preprocessor),
    ('model', xgb.XGBRegressor())
])
```

---

## üìå –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è

### üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ One-Hot Encoding –∫ –∫–æ–ª–æ–Ω–∫–µ "product_type" —Å 5 –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º–∏.
2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ Frequency Encoding –¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ "country" (50 —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π).

### üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –°—Ä–∞–≤–Ω–∏—Ç–µ Target Encoding –∏ CatBoost Encoding –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ House Prices.
2. –†–µ–∞–ª–∏–∑—É–π—Ç–µ —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏–µ –≤ —Ä—É—á–Ω–æ–º Target Encoding —Å alpha=10.

### üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö —Ä—è–¥–æ–≤ (—Å —Å–æ–±–ª—é–¥–µ–Ω–∏–µ–º –ø–æ—Ä—è–¥–∫–∞).
2. –°–æ–∑–¥–∞–π—Ç–µ –∞–Ω—Å–∞–º–±–ª—å –∏–∑ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∑–∞–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–∞–∑–Ω—ã–º–∏ –º–µ—Ç–æ–¥–∞–º–∏.

---

```python
# –ü—Ä–∏–º–µ—Ä —Ä–µ—à–µ–Ω–∏—è üü¢ –ó–∞–¥–∞–Ω–∏—è 1
data = pd.DataFrame({'product_type': ['A', 'B', 'C', 'A', 'D']})
ohe = OneHotEncoder(sparse_output=False)
encoded = ohe.fit_transform(data[['product_type']])
print(encoded)
```

---

## üìå –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
1. **–í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏:**
   - –õ–∏–Ω–µ–π–Ω—ã–µ –º–æ–¥–µ–ª–∏: One-Hot (–¥–æ 20 –∫–∞—Ç–µ–≥–æ—Ä–∏–π)
   - –î–µ—Ä–µ–≤—å—è/–±—É—Å—Ç–∏–Ω–≥–∏: Target Encoding
2. **–í—Å–µ–≥–¥–∞ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–π—Ç–µ —É—Ç–µ—á–∫–∏:**
   - –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–æ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
   - –ö—Ä–æ—Å—Å-–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–µ —Å—Ö–µ–º—ã
   - Ordered encoding (CatBoost)
3. **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —Å –∫–æ–º–±–∏–Ω–∞—Ü–∏—è–º–∏:**
   - One-Hot + Target Encoding
   - –ß–∞—Å—Ç–æ—Ç—ã + Embeddings
4. **–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–π—Ç–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å:**
   - –£–º–µ–Ω—å—à–µ–Ω–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–¥–∫–∏—Ö)
   - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è

–ü–æ–º–Ω–∏—Ç–µ: –Ω–µ—Ç "—Å–µ—Ä–µ–±—Ä—è–Ω–æ–π –ø—É–ª–∏" - —Ç–µ—Å—Ç–∏—Ä—É–π—Ç–µ —Ä–∞–∑–Ω—ã–µ –ø–æ–¥—Ö–æ–¥—ã –¥–ª—è –≤–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö!
