## Этапы работы в ML

Помимо модели, функции потерь и метрик, в машинном обучении нужно выбирать ещё:

---

### **1. Стратегия работы с данными**
| **Что выбирать**       | **Варианты**                                                                 | **Когда применять**                     |
|------------------------|-----------------------------------------------------------------------------|-----------------------------------------|
| **Разбиение данных**    | Train/Test/Val (70/15/15), K-Fold, Time Series Split                       | Зависит от размера данных и типа задачи |
| **Балансировка**       | Undersampling, Oversampling, SMOTE, Class Weights                          | При дисбалансе классов                 |
| **Аугментация**        | Для изображений: повороты, crop; Для текста: synonym replacement           | Когда мало тренировочных данных         |
| **Контроль утечки**    | Временные ряды: запрет на будущие данные; Кросс-валидация: GroupKFold      | Чтобы избежать overfitting              |

---

### **2. Инженерия признаков (Feature Engineering)**
| **Тип данных**         | **Методы обработки**                                                      | **Примеры**                             |
|------------------------|--------------------------------------------------------------------------|-----------------------------------------|
| **Числовые**           | Стандартизация (StandardScaler), Нормализация (MinMax), Log-преобразование | Для линейных моделей                    |
| **Категориальные**     | One-Hot, Target Encoding, Embedding (для нейросетей)                     | Зависит от количества категорий         |
| **Текст**              | TF-IDF, Word2Vec, BERT-эмбеддинги                                       | Для задач NLP                           |
| **Временные ряды**     | Создание лагов, скользящие средние, Fourier-фичи                        | Для ARIMA/LSTM                          |
| **Геоданные**          | Извлечение расстояний, кластеризация точек                              | Для задач с картами                     |

---

### **3. Оптимизация и регуляризация**
| **Компонент**          | **Выбор**                                                                | **Зачем?**                              |
|------------------------|--------------------------------------------------------------------------|-----------------------------------------|
| **Оптимизатор**        | SGD, Adam, RMSprop (для нейросетей)                                     | Скорость и стабильность обучения        |
| **Регуляризация**      | L1/L2-нормы, Dropout, Early Stopping                                    | Борьба с переобучением                  |
| **Скорость обучения**  | Поиск по сетке (GridSearch), Циклические LR (Cyclical Learning Rates)   | Для быстрой сходимости                  |
| **Батч-нормализация**  | BatchNorm, LayerNorm (для нейросетей)                                   | Стабилизация обучения                   |

---

### **4. Интерпретация модели**
| **Метод**              | **Применимость**                                                        | **Пример использования**               |
|------------------------|--------------------------------------------------------------------------|-----------------------------------------|
| **SHAP/LIME**          | Для любых моделей                                                       | Объяснение предсказаний                 |
| **Feature Importance** | Для деревьев (Random Forest, XGBoost)                                   | Выбор ключевых признаков                |
| **Attention Maps**     | Для нейросетей (CNN, Transformer)                                       | Анализ важных областей на изображениях  |

---

### **5. Деплой и мониторинг**
| **Этап**               | **Решения**                                                             | **Инструменты**                         |
|------------------------|--------------------------------------------------------------------------|-----------------------------------------|
| **Формат модели**      | ONNX, Pickle, TF Serving                                                | Для продакшена                          |
| **Мониторинг**         | Drift-детекция (Evidently), Логирование метрик (MLflow)                 | Контроль качества предсказаний          |
| **A/B-тестирование**   | Canary-развертывание, Shadow Mode                                       | Сравнение новой и старой моделей        |

---

### **Дополнительные стратегии**
| **Стратегия**          | **Применение**                                                          | **Пример**                              |
|------------------------|--------------------------------------------------------------------------|-----------------------------------------|
| **Ансамбли**           | Stacking, Blending, Bagging                                            | Улучшение точности                      |
| **Активное обучение**  | Когда разметка данных дорогая                                           | Выбор наиболее информативных примеров   |
| **Distributed Learning**| Для очень больших данных                                               | Horovod, Ray                           |

---

### **Пример полного пайплайна для бинарной классификации**
1. **Данные**: 
   - Балансировка через SMOTE (если дисбаланс 1:10)
   - Кодировка категориальных фичей: Target Encoding
2. **Модель**: 
   - Основная: XGBoost с L2-регуляризацией
   - Альтернатива: Logistic Regression (если нужна интерпретируемость)
3. **Оптимизация**: 
   - Оптимизатор: Adam (для нейросетей)
   - Поиск гиперпараметров: Bayesian Optimization
4. **Интерпретация**: 
   - SHAP-значения для анализа важности фичей
5. **Деплой**: 
   - Экспорт в ONNX-формат
   - Мониторинг дрифта: раз в неделю

---

### **Чек-лист для школьников**
1. Всегда начинай с **анализа данных** (разведочный анализ, EDA).
2. Для табличных данных пробуй **сначала простые модели** (Logistic Regression).
3. **Не забывай про baseline** (например, предсказывать самый частый класс).
4. **Документируй все эксперименты** (метрики, параметры).
5. **Тестируй на "глупых" данных** (например, зашумлённых) — это проверка устойчивости модели.

Этот список охватывает **все ключевые этапы** — от подготовки данных до продакшена. Для олимпиад можно фокусироваться на первых 4-х пунктах, но понимание полного цикла сделает решения сильнее!
