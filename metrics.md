```python
# –ì–ª–∞–≤–∞ 22: –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ ‚Äì MAE, Accuracy, F1
# –£—Ä–æ–≤–Ω–∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: üü¢ –ë–∞–∑–æ–≤—ã–π | üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π | üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π

import numpy as np
from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score
from sklearn.metrics import precision_score, recall_score, roc_auc_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# !pip install scikit-learn
```

---

## üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å (–û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏)

### 1.1 MAE (Mean Absolute Error)
**–î–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:** –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞  
$MAE = \frac{1}{N}\sum|y_i - \hat{y}_i|$

```python
y_true = np.array([3.0, 5.0, 2.5, 7.0])
y_pred = np.array([2.5, 5.0, 3.0, 8.0])
mae = mean_absolute_error(y_true, y_pred)
print(f"MAE: {mae:.2f}")  # (0.5+0+0.5+1)/4 = 0.5
```

### 1.2 Accuracy (–¢–æ—á–Ω–æ—Å—Ç—å)
**–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:** –î–æ–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤  
$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$

```python
y_true = [0, 1, 0, 1, 1]
y_pred = [0, 1, 0, 0, 1]
acc = accuracy_score(y_true, y_pred)
print(f"Accuracy: {acc:.2f}")  # 4/5 = 0.8
```

### 1.3 F1-Score
**–ì–∞—Ä–º–æ–Ω–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥–Ω–µ–µ precision –∏ recall:**  
$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$

```python
f1 = f1_score(y_true, y_pred)
print(f"F1-Score: {f1:.2f}")  # Precision=0.67, Recall=0.67 ‚Üí F1=0.67
```

---

## üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å (–í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏)

### 2.1 –ö–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏?
| **–ó–∞–¥–∞—á–∞**               | **–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–µ—Ç—Ä–∏–∫–∏**       |
|--------------------------|---------------------------------|
| –ë–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è   | F1, AUC-ROC, Precision, Recall  |
| –ú—É–ª—å—Ç–∏–∫–ª–∞—Å—Å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è| F1-macro, Accuracy              |
| –†–µ–≥—Ä–µ—Å—Å–∏—è                | MAE, MSE, R¬≤                    |
| –†–∞–Ω–∂–∏—Ä–æ–≤–∞–Ω–∏–µ             | NDCG, MAP                       |

### 2.2 –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
```python
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ')
plt.ylabel('–ò—Å—Ç–∏–Ω–∞')
plt.title('–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫')
plt.show()
```

### 2.3 Precision-Recall Tradeoff
```python
# –†–∞—Å—á–µ—Ç –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ø–æ—Ä–æ–≥–æ–≤
thresholds = np.linspace(0, 1, 50)
precisions = []
recalls = []

y_probs = [0.1, 0.9, 0.4, 0.6, 0.7]  # –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫–ª–∞—Å—Å–∞ 1

for thresh in thresholds:
    y_pred_thresh = [1 if prob > thresh else 0 for prob in y_probs]
    precisions.append(precision_score(y_true, y_pred_thresh))
    recalls.append(recall_score(y_true, y_pred_thresh))

# –ö—Ä–∏–≤–∞—è Precision-Recall
plt.plot(recalls, precisions)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('–ö—Ä–∏–≤–∞—è Precision-Recall')
plt.show()
```

---

## üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å (–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏)

### 3.1 –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
```python
def weighted_accuracy(y_true, y_pred, weights=[0.5, 2.0]):
    """–í–µ—Å –æ—à–∏–±–æ–∫ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–ª–∞—Å—Å–æ–≤"""
    correct = np.zeros(len(y_true))
    for i, (true, pred) in enumerate(zip(y_true, y_pred)):
        if true == pred:
            correct[i] = weights[true]  # –í–µ—Å –∑–∞ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –∫–ª–∞—Å—Å–∞
    return np.mean(correct)

print(f"Weighted Accuracy: {weighted_accuracy(y_true, y_pred):.2f}")
```

### 3.2 –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–º–µ—Ç—Ä–∏–∫
```python
def profit_metric(y_true, y_pred):
    """–ü—Ä–∏–º–µ—Ä: FP —Å—Ç–æ–∏—Ç 1$, FN —Å—Ç–æ–∏—Ç 5$"""
    cm = confusion_matrix(y_true, y_pred)
    tn, fp, fn, tp = cm.ravel()
    return tp*10 - fp*1 - fn*5  # –ü—Ä–∏–±—ã–ª—å

print(f"Business Profit: ${profit_metric(y_true, y_pred)}")
```

### 3.3 –ö—Ä–æ—Å—Å-—ç–Ω—Ç—Ä–æ–ø–∏—è –∏ –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ –ø–æ—Ç–µ—Ä–∏
```python
from sklearn.metrics import log_loss

y_true_proba = [0, 1, 0, 1]  # –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π
y_pred_proba = [0.1, 0.9, 0.2, 0.8]
logloss = log_loss(y_true_proba, y_pred_proba)
print(f"LogLoss: {logloss:.4f}")  # –ß–µ–º –º–µ–Ω—å—à–µ, —Ç–µ–º –ª—É—á—à–µ
```

### 3.4 –ö—Ä–∏–≤—ã–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
```python
from sklearn.model_selection import validation_curve
from sklearn.ensemble import RandomForestClassifier

param_range = [10, 50, 100, 200]  # n_estimators
train_scores, test_scores = validation_curve(
    RandomForestClassifier(),
    X, y,
    param_name="n_estimators",
    param_range=param_range,
    cv=5,
    scoring='f1'
)

plt.plot(param_range, np.mean(train_scores, axis=1), label='Train')
plt.plot(param_range, np.mean(test_scores, axis=1), label='Validation')
plt.legend()
plt.title('–í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –∫—Ä–∏–≤–∞—è F1-Score')
plt.xlabel('n_estimators')
plt.ylabel('F1')
plt.show()
```

---

## üìä –ß–µ–∫–ª–∏—Å—Ç –ø–æ —É—Ä–æ–≤–Ω—è–º

| –£—Ä–æ–≤–µ–Ω—å | –ù–∞–≤—ã–∫–∏ |
|---------|--------|
| üü¢ | –†–∞—Å—á–µ—Ç MAE, Accuracy, F1 –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–ª—É—á–∞–µ–≤ |
| üü° | –ê–Ω–∞–ª–∏–∑ –º–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫, –∫—Ä–∏–≤—ã–µ PR, –≤—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫ |
| üî¥ | –ö–∞—Å—Ç–æ–º–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏, –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –±–∏–∑–Ω–µ—Å-–ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–π |

---

## ‚ö†Ô∏è –ê–Ω—Ç–∏–ø–∞—Ç—Ç–µ—Ä–Ω—ã
1. **–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ Accuracy –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ** (99% –∫–ª–∞—Å—Å–∞ 0 ‚Üí Accuracy 99%)
2. **–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è F1 –±–µ–∑ —É—á–µ—Ç–∞ business context** (—Ä–∞–∑–Ω–∞—è —Ü–µ–Ω–∞ FP/FN)
3. **–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ —Ä–∞–∑–Ω—ã–º –º–µ—Ç—Ä–∏–∫–∞–º** (F1 vs AUC-ROC)
4. **–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–≤** –¥–ª—è –º–µ—Ç—Ä–∏–∫

---

## üöÄ –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Å–æ–≤–µ—Ç—ã
1. **–í—ã–±–æ—Ä –ø–æ—Ä–æ–≥–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏:**
```python
from sklearn.metrics import precision_recall_curve

precisions, recalls, thresholds = precision_recall_curve(y_true, y_probs)
f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-8)
best_threshold = thresholds[np.argmax(f1_scores)]
print(f"–û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥: {best_threshold:.2f}")
```

2. **–ë—É—Ç—Å—Ç—Ä—ç–ø –æ—Ü–µ–Ω–æ–∫:**
```python
def bootstrap_metric(y_true, y_pred, metric, n_bootstrap=1000):
    scores = []
    for _ in range(n_bootstrap):
        indices = np.random.choice(len(y_true), size=len(y_true), replace=True)
        scores.append(metric(y_true[indices], y_pred[indices]))
    return np.percentile(scores, [2.5, 97.5])

print(f"95% CI –¥–ª—è F1: {bootstrap_metric(y_true, y_pred, f1_score)}")
```

3. **–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π:**
```python
from sklearn.calibration import CalibratedClassifierCV

model = RandomForestClassifier()
calibrated = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated.fit(X_train, y_train)
calibrated_probs = calibrated.predict_proba(X_test)[:, 1]
```

---

## üìå –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã–µ –∑–∞–¥–∞–Ω–∏—è

### üü¢ –ë–∞–∑–æ–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ MAE –¥–ª—è y_true=[10, 20, 30], y_pred=[12, 18, 28].
2. –í—ã—á–∏—Å–ª–∏—Ç–µ Accuracy –¥–ª—è y_true=[1,0,1,0], y_pred=[1,1,1,0].

### üü° –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –î–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å y_true=[1,0,1,1,0], y_pred=[1,0,0,1,0]:
   - –ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–∞—Ç—Ä–∏—Ü—É –æ—à–∏–±–æ–∫
   - –†–∞—Å—Å—á–∏—Ç–∞–π—Ç–µ Precision, Recall, F1
2. –û–±—ä—è—Å–Ω–∏—Ç–µ, –ø–æ—á–µ–º—É F1 –ª—É—á—à–µ Accuracy –ø—Ä–∏ –¥–∏—Å–±–∞–ª–∞–Ω—Å–µ.

### üî¥ –≠–∫—Å–ø–µ—Ä—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å
1. –†–µ–∞–ª–∏–∑—É–π—Ç–µ –º–µ—Ç—Ä–∏–∫—É Cohen's Kappa.
2. –°–æ–∑–¥–∞–π—Ç–µ –∫–∞—Å—Ç–æ–º–Ω—É—é –º–µ—Ç—Ä–∏–∫—É, –≥–¥–µ –æ—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∞ 1 –≤ 5 —Ä–∞–∑ –≤–∞–∂–Ω–µ–µ –∫–ª–∞—Å—Å–∞ 0.

---

```python
# –ü—Ä–∏–º–µ—Ä —Ä–µ—à–µ–Ω–∏—è üü¢ –ó–∞–¥–∞–Ω–∏—è 1
y_true = np.array([10, 20, 30])
y_pred = np.array([12, 18, 28])
mae = np.mean(np.abs(y_true - y_pred))
print(f"MAE: {mae:.1f}")  # (2+2+2)/3 = 2.0
```

---

## üìå –ó–∞–∫–ª—é—á–µ–Ω–∏–µ
–ö–ª—é—á–µ–≤—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
1. **–í—ã–±–æ—Ä –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏**:
   - –ë–∏–∑–Ω–µ—Å-—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è > —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∏–µ –º–µ—Ç—Ä–∏–∫–∏
   - –î–∏—Å–±–∞–ª–∞–Ω—Å ‚Üí F1, AUC-ROC
   - –†–µ–≥—Ä–µ—Å—Å–∏—è ‚Üí MAE (–∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ–º–æ—Å—Ç—å), MSE (—à—Ç—Ä–∞—Ñ –∑–∞ –±–æ–ª—å—à–∏–µ –æ—à–∏–±–∫–∏)
2. **–í—Å–µ–≥–¥–∞ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ –æ—à–∏–±–∫–∏**:
   - –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫ > Accuracy
   - –ö—Ä–∏–≤—ã–µ PR/ROC > F1
3. **–°—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–∞—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å**:
   - –î–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
   - –ë—É—Ç—Å—Ç—Ä—ç–ø –æ—Ü–µ–Ω–∫–∏
4. **–ö–∞–ª–∏–±—Ä–æ–≤–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π** –¥–ª—è –∑–∞–¥–∞—á —Å –ø–æ—Ä–æ–≥–∞–º–∏

–ü–æ–º–Ω–∏—Ç–µ: –Ω–µ—Ç "–ª—É—á—à–µ–π" –º–µ—Ç—Ä–∏–∫–∏ ‚Äî –µ—Å—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ–¥—Ö–æ–¥—è—â–∞—è –¥–ª—è –≤–∞—à–µ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏!
